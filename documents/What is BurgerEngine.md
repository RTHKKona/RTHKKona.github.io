A quick discussion and blog about my tool BurgerEngine:
In order to improve my commission-based workflow, I tried my hand at file conversions via raw pcm s16le data into opus, which led to a few months of research and discovery to eventually succeed in the public with the Handburger Modkit v1. After it was developed with an overwhelming amount of bloat of Python, I decided to change it to a mainly Batch script-based pipeline workflow, ultimately leading to the revamping into HBMK-IFRIT, found on GameBanana.

This - however - made me desire a new tool, a tool to end all tools one might say. Which my answer to this burning question was BurgerEngine. BurgerEngine is separated into three distinct workflows, the first one being The Obliterator, the second The Gravekeeper, and the third The Dreamcatcher. Each component acts as a specialized stage in a comprehensive audio modding pipeline, designed to automate tasks, ensure data integrity, and dramatically reduce the potential for human error.

Workflow 1: Obliterator - Metadata Extraction
    The first stage of the pipeline, "Obliterator," is responsible for data extraction and preparation. Its primary role is to bridge the gap between the creative work done in an audio editor and the technical data required for in-game implementation.

    It begins by scanning a directory of Audacity projects (.aup3 files). Using an external command-line utility, it extracts the raw project data into a structured XML format.The tool then parses this XML, searching for specific labels that I place during the audio editing phase, such as loop start, loop end, and total samples. This process transforms time-based markers from the audio project into precise, sample-accurate integer values. Finally, Obliterator populates a central commission-tracking Excel spreadsheet with this critical data. It also resolves simplified "shortcodes" (e.g., map12, questclear) into their full, technical in-game filenames using a configurable JSON file. This stage essentially prepares a master worklist for the rest of the pipeline, enriching it with metadata that would otherwise have to be found and entered by hand.

Workflow 2: Gravekeeper - Audio Processing & Conversion
    With the metadata prepared, "The Gravekeeper" takes over to handle the audio files themselves. This stage is the workhorse of the operation, performing file conversion, editing, and organization. Gravekeeper reads the enriched Excel file and matches entries to their corresponding source .wav files. It then calls a custom-built batch script that leverages external tools to convert the high-quality WAV audio into the game-ready Opus format. Its most critical task is performing a direct, binary-level edit on the header of each newly created .opus file. It opens the file in binary write mode and injects the loop start and loop end sample values—read from the Excel sheet—into the precise byte offsets where the game engine expects to find them.

    After embedding the loop points, it updates the Excel sheet with the final file size of the Opus file and renames the audio file to its final in-game name. The files are then moved to a dedicated output directory, ready for the final integration step.

Workflow 3: Dreamcatcher - Game Data Integration
    The final and most delicate stage is "Dreamcatcher." This component is responsible for integrating the newly created audio and its metadata into a proprietary, engine-specific binary file format known as STQR. This tool reads the target .stqr file, a complex binary structure that contains an index of all audio streams for a given area or category in the game. It parses the file's header and iterates through an array of data structures, each one corresponding to a single audio track.
    Dreamcatcher matches the file paths within the STQR file to the "Real Name" entries in the master Excel sheet. Once a match is confirmed, it uses the data from the spreadsheet (File Size, Total Samples, Loop Start, Loop End, Sample Rate, etc.) to overwrite the existing values within that specific data structure in the STQR file. This is all done in memory on a byte array of the file. After all updates are applied, it performs sanity checks (like ensuring the file size hasn't changed) before saving the modified byte array back to disk, overwriting the original STQR file after creating a backup.

All three workflows are tied together in user-friendly GUI built with Python's native tkinter library. It features persistent settings, threaded operations to prevent the UI from freezing, a detailed logging window for diagnostics, and progress bars to provide real-time feedback. It is a complete, end-to-end solution that turns a multi-hour, error-prone manual process into a reliable, few-minute automated task, allowing me to focus more on the creative aspects of my commission work.